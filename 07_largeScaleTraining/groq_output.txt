Changes that were made to the file:

def evaluate_bert_tiny(rebuild_policy=None, should_execute=True):
    # set seed for consistency
    np.random.seed(1)
    torch.manual_seed(0)
    os.environ["TOKENIZERS_PARALLELISM"] = "false"

    # load pre-trained torch model
    pytorch_model, tokenizer = get_model()
    
    input_text = "If you prick us do we not bleed? If you tickle us do we not laught?  If you poison us do we not die? And if you wrong us shall we not revenge?"
    encoded_input = tokenizer.encode(input_text, max_length=128, padding='max_length', truncation=True)
    input_ids = encoded_input
    attention_mask = [1]*len(input_ids)
    # dummy inputs to generate the groq model
    batch_size = 1
    max_seq_length = 128
    dummy_inputs = {
        "input_ids": torch.ones(batch_size, max_seq_length, dtype=torch.long),
        "attention_mask": torch.ones(batch_size, max_seq_length, dtype=torch.bool),
    }
    custom_inputs = {
        "input_ids": torch.tensor([input_ids],dtype=torch.long),
        "attention_mask": torch.tensor([attention_mask],dtype=torch.bool),
    }


    # generate groq model
    groq_model = groqit(pytorch_model, custom_inputs, rebuild=rebuild_policy)
    #groq_model = groqit(pytorch_model, dummy_inputs, rebuild=rebuild_policy)

    # compute performance on CPU and GroqChip
    if should_execute:
        compute_performance(
            groq_model,
            pytorch_model,
            dataset="sst",
            tokenizer=tokenizer,
            max_seq_length=max_seq_length,
            task="classification",
        )

    print(f"Proof point {__file__} finished!")

Output

(groqflow) lindsey@groq-r01-gn-08:~/groqflow/proof_points/natural_language_processing/bert$ python bert_tiny.py
/home/lindsey/miniconda3/envs/groqflow/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()

Woohoo! Build "bert_tiny" (build_name auto-selected) found in cache. Loading it!
Preprocessing data.
/home/lindsey/.local/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for sst contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/sst
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(

Info: No inputs received for benchmark. Using the inputs provided during model compilation.
Running inference on GroqChip.
Running inference using PyTorch model (CPU).
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2210/2210 [00:04<00:00, 444.15it/s]
+--------+----------+-------------------------+----------------+----------------------+-------------+
| Source | Accuracy | end-to-end latency (ms) | end-to-end IPS | on-chip latency (ms) | on-chip IPS |
+--------+----------+-------------------------+----------------+----------------------+-------------+
|  cpu   |  77.47%  |           2.25          |     443.95     |          --          |      --     |
|  groq  |  77.47%  |           0.07          |    15352.46    |         0.03         |   37576.72  |
+--------+----------+-------------------------+----------------+----------------------+-------------+
Proof point /home/lindsey/groqflow/proof_points/natural_language_processing/bert/bert_tiny.py finished!
(groqflow) lindsey@groq-r01-gn-08:~/groqflow/proof_points/natural_language_processing/bert$ vi bert_tiny.py 
(groqflow) lindsey@groq-r01-gn-08:~/groqflow/proof_points/natural_language_processing/bert$ python bert_tiny.py
/home/lindsey/miniconda3/envs/groqflow/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()

Woohoo! Build "bert_tiny" (build_name auto-selected) found in cache. Loading it!
Preprocessing data.
/home/lindsey/.local/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for sst contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/sst
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(

Info: No inputs received for benchmark. Using the inputs provided during model compilation.
Running inference on GroqChip.
Running inference using PyTorch model (CPU).
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2210/2210 [00:04<00:00, 445.92it/s]
+--------+----------+-------------------------+----------------+----------------------+-------------+
| Source | Accuracy | end-to-end latency (ms) | end-to-end IPS | on-chip latency (ms) | on-chip IPS |
+--------+----------+-------------------------+----------------+----------------------+-------------+
|  cpu   |  77.47%  |           2.24          |     445.70     |          --          |      --     |
|  groq  |  77.47%  |           0.05          |    18527.86    |         0.03         |   37576.72  |
+--------+----------+-------------------------+----------------+----------------------+-------------+
Proof point /home/lindsey/groqflow/proof_points/natural_language_processing/bert/bert_tiny.py finished!
