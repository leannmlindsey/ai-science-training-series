2024-04-10 00:04:28,175 INFO:   Effective batch size is 512.
2024-04-10 00:04:28,200 INFO:   Checkpoint autoloading is enabled. Looking for latest checkpoint in "model_dir_bert_large_pytorch" directory with the following naming convention: `checkpoint_(step)(_timestamp)?.mdl`.
2024-04-10 00:04:28,202 INFO:   No checkpoints were found in "model_dir_bert_large_pytorch".
2024-04-10 00:04:28,202 INFO:   No checkpoint was provided. Using randomly initialized model parameters.
2024-04-10 00:04:29,532 INFO:   Saving checkpoint at step 0
2024-04-10 00:05:02,700 INFO:   Saved checkpoint model_dir_bert_large_pytorch/checkpoint_0.mdl
2024-04-10 00:05:19,003 INFO:   Compiling the model. This may take a few minutes.
2024-04-10 00:05:19,004 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.
2024-04-10 00:05:21,280 INFO:   Initiating a new image build job against the cluster server.
2024-04-10 00:05:21,410 INFO:   Custom worker image build is disabled from server.
2024-04-10 00:05:21,423 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.
2024-04-10 00:05:21,747 INFO:   Initiating a new compile wsjob against the cluster server.
2024-04-10 00:05:21,861 INFO:   compile job id: wsjob-hfj6g6sqghoc2dtjbn7acv, remote log path: /n1/wsjob/workdir/job-operator/wsjob-hfj6g6sqghoc2dtjbn7acv
2024-04-10 00:05:31,903 INFO:   Poll ingress status: Waiting for job running, current job status: Queueing, msg: job is queueing. Job queue status: current job is top of queue but likely blocked by running jobs, 1 compile job(s) running using 67Gi memory. For more information, please run 'csctl get jobs'.
2024-04-10 00:20:22,377 INFO:   Poll ingress status: Waiting for job running, current job status: Queueing, msg: job is queueing. Job queue status: current job is top of queue but likely blocked by running jobs, 1 execute job(s) running using 1 system(s), 1 compile job(s) running using 67Gi memory. For more information, please run 'csctl get jobs'.
2024-04-10 00:20:32,382 INFO:   Poll ingress status: Waiting for job running, current job status: Scheduled, msg: job is scheduled. 
2024-04-10 00:20:42,396 INFO:   Poll ingress status: Waiting for job service readiness.
2024-04-10 00:21:02,417 INFO:   Ingress is ready: Job ingress ready, poll ingress success.
2024-04-10 00:21:06,291 INFO:   Pre-optimization transforms...
2024-04-10 00:21:12,190 INFO:   Optimizing layouts and memory usage...
2024-04-10 00:21:12,234 INFO:   Gradient accumulation enabled
2024-04-10 00:21:12,235 WARNING:   Gradient accumulation will search for an optimal micro batch size based on internal performance models, which can lead to an increased compile time. Specify `micro_batch_size` option in the 'train_input/eval_input' section of your .yaml parameter file to set the gradient accumulation microbatch size, if an optimal microbatch size is known.

2024-04-10 00:21:12,237 INFO:   Gradient accumulation trying sub-batch size 8...
2024-04-10 00:21:17,158 INFO:   Exploring floorplans
2024-04-10 00:21:23,854 INFO:   Exploring data layouts
2024-04-10 00:21:36,077 INFO:   Optimizing memory usage
2024-04-10 00:22:23,769 INFO:   Gradient accumulation trying sub-batch size 64...
2024-04-10 00:22:30,365 INFO:   Exploring floorplans
2024-04-10 00:22:39,810 INFO:   Exploring data layouts
2024-04-10 00:22:57,818 INFO:   Optimizing memory usage
2024-04-10 00:23:30,706 INFO:   Gradient accumulation trying sub-batch size 32...
2024-04-10 00:23:36,811 INFO:   Exploring floorplans
2024-04-10 00:23:44,438 INFO:   Exploring data layouts
2024-04-10 00:23:58,805 INFO:   Optimizing memory usage
2024-04-10 00:24:34,191 INFO:   Gradient accumulation trying sub-batch size 128...
2024-04-10 00:24:39,676 INFO:   Exploring floorplans
2024-04-10 00:24:50,693 INFO:   Exploring data layouts
2024-04-10 00:25:10,863 INFO:   Optimizing memory usage
2024-04-10 00:25:40,775 INFO:   Gradient accumulation trying sub-batch size 256...
2024-04-10 00:25:46,320 INFO:   Exploring floorplans
2024-04-10 00:26:03,536 INFO:   Exploring data layouts
2024-04-10 00:26:27,768 INFO:   Optimizing memory usage
2024-04-10 00:27:10,331 INFO:   Exploring floorplans
2024-04-10 00:27:14,198 INFO:   Exploring data layouts
2024-04-10 00:27:46,499 INFO:   Optimizing memory usage
2024-04-10 00:28:21,929 INFO:   No benefit from gradient accumulation expected. Compile will proceed at original per-box batch size 512 with 6 lanes

2024-04-10 00:28:21,983 INFO:   Post-layout optimizations...
2024-04-10 00:28:36,773 INFO:   Allocating buffers...
2024-04-10 00:28:40,380 INFO:   Code generation...
2024-04-10 00:28:55,798 INFO:   Compiling image...
2024-04-10 00:28:55,804 INFO:   Compiling kernels
2024-04-10 00:32:19,114 INFO:   Compiling final image
2024-04-10 00:35:15,734 INFO:   Compile artifacts successfully written to remote compile directory. Compile hash is: cs_8939750200954608837
2024-04-10 00:35:15,797 INFO:   Heartbeat thread stopped for wsjob-hfj6g6sqghoc2dtjbn7acv.
2024-04-10 00:35:15,799 INFO:   Compile was successful!
2024-04-10 00:35:15,803 INFO:   Programming Cerebras Wafer Scale Cluster for execution. This may take a few minutes.
2024-04-10 00:35:18,056 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.
2024-04-10 00:35:18,404 INFO:   Initiating a new execute wsjob against the cluster server.
2024-04-10 00:35:18,536 INFO:   execute job id: wsjob-fyjvt67wsfqzx7nvrvwarf, remote log path: /n1/wsjob/workdir/job-operator/wsjob-fyjvt67wsfqzx7nvrvwarf
2024-04-10 00:35:28,578 INFO:   Poll ingress status: Waiting for job service readiness.
2024-04-10 00:35:58,615 INFO:   Ingress is ready: Job ingress ready, poll ingress success.
2024-04-10 00:35:58,776 INFO:   Preparing to execute using 1 CSX
2024-04-10 00:36:28,167 INFO:   About to send initial weights
2024-04-10 00:37:03,807 INFO:   Finished sending initial weights
2024-04-10 00:37:03,809 INFO:   Finalizing appliance staging for the run
2024-04-10 00:37:03,832 INFO:   Waiting for device programming to complete
2024-04-10 00:38:58,313 INFO:   Device programming is complete
2024-04-10 00:38:59,024 INFO:   Using network type: ROCE
2024-04-10 00:38:59,025 INFO:   Waiting for input workers to prime the data pipeline and begin streaming ...
2024-04-10 00:38:59,050 INFO:   Input workers have begun streaming input data
2024-04-10 00:39:15,791 INFO:   Appliance staging is complete
2024-04-10 00:39:15,797 INFO:   Beginning appliance run
2024-04-10 00:39:33,042 INFO:   | Train Device=CSX, Step=100, Loss=9.39062, Rate=2977.91 samples/sec, GlobalRate=2977.91 samples/sec
2024-04-10 00:39:50,715 INFO:   | Train Device=CSX, Step=200, Loss=8.70312, Rate=2929.45 samples/sec, GlobalRate=2936.97 samples/sec
2024-04-10 00:40:08,250 INFO:   | Train Device=CSX, Step=300, Loss=7.79688, Rate=2923.68 samples/sec, GlobalRate=2931.23 samples/sec
2024-04-10 00:40:25,697 INFO:   | Train Device=CSX, Step=400, Loss=7.39062, Rate=2930.20 samples/sec, GlobalRate=2932.06 samples/sec
2024-04-10 00:40:43,292 INFO:   | Train Device=CSX, Step=500, Loss=7.80469, Rate=2918.07 samples/sec, GlobalRate=2927.62 samples/sec
2024-04-10 00:41:00,722 INFO:   | Train Device=CSX, Step=600, Loss=7.53125, Rate=2929.73 samples/sec, GlobalRate=2929.26 samples/sec
2024-04-10 00:41:18,438 INFO:   | Train Device=CSX, Step=700, Loss=7.35156, Rate=2905.89 samples/sec, GlobalRate=2923.59 samples/sec
2024-04-10 00:41:36,101 INFO:   | Train Device=CSX, Step=800, Loss=7.27344, Rate=2901.57 samples/sec, GlobalRate=2920.45 samples/sec
2024-04-10 00:41:53,830 INFO:   | Train Device=CSX, Step=900, Loss=7.35938, Rate=2893.34 samples/sec, GlobalRate=2916.79 samples/sec
2024-04-10 00:42:11,509 INFO:   | Train Device=CSX, Step=1000, Loss=7.12500, Rate=2895.07 samples/sec, GlobalRate=2914.72 samples/sec
2024-04-10 00:42:11,509 INFO:   Saving checkpoint at step 1000
2024-04-10 00:42:48,686 INFO:   Saved checkpoint model_dir_bert_large_pytorch/checkpoint_1000.mdl
2024-04-10 00:43:23,449 INFO:   Heartbeat thread stopped for wsjob-fyjvt67wsfqzx7nvrvwarf.
2024-04-10 00:43:23,457 INFO:   Training completed successfully!
2024-04-10 00:43:23,457 INFO:   Processed 512000 sample(s) in 175.659945273 seconds.
